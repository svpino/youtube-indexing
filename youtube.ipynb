{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt --quiet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YouTube Indexing\n",
    "\n",
    "This is a simple example of how to use OpenAI's Whisper with Pinecone and the OpenAI API to ask questions about any videos on YouTube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/svpino/miniforge3/lib/python3.10/site-packages/pinecone/index.py:4: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import whisper\n",
    "import tiktoken\n",
    "import openai\n",
    "import pinecone\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pytube import YouTube\n",
    "from uuid import uuid4\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_API_ENV = os.getenv(\"PINECONE_API_ENV\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcribing YouTube Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUTUBE_VIDEOS = [\n",
    "#     \"https://www.youtube.com/watch?v=nNwE0sQq39w\",\n",
    "#     \"https://www.youtube.com/watch?v=rUBw_F5uV4Q\",\n",
    "#     \"https://www.youtube.com/watch?v=Y1-s37zrm1M\",\n",
    "#     \"https://www.youtube.com/watch?v=9uTlRae2uQs\",\n",
    "#     \"https://www.youtube.com/watch?v=7N_hJLl-BK8\",\n",
    "# ]\n",
    "YOUTUBE_VIDEOS = [\"https://www.youtube.com/watch?v=cdiD-9MMpb0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Andrej Karpathy Tesla AI Self-Driving Optimus ...</td>\n",
       "      <td>https://www.youtube.com/watch?v=cdiD-9MMpb0</td>\n",
       "      <td>I think it's possible that physics has exploit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title   \n",
       "0  Andrej Karpathy Tesla AI Self-Driving Optimus ...  \\\n",
       "\n",
       "                                           url   \n",
       "0  https://www.youtube.com/watch?v=cdiD-9MMpb0  \\\n",
       "\n",
       "                                                text  \n",
       "0  I think it's possible that physics has exploit...  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transcribe(youtube_url, model):\n",
    "    youtube = YouTube(youtube_url)\n",
    "\n",
    "    audio = youtube.streams.filter(only_audio=True).first()\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        file = audio.download(output_path=tmpdir)\n",
    "        title = os.path.basename(file)[:-4]\n",
    "        result = model.transcribe(file, fp16=False)\n",
    "\n",
    "    return title, youtube_url, result[\"text\"].strip()\n",
    "\n",
    "\n",
    "transcriptions = []\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "for youtube_url in YOUTUBE_VIDEOS:\n",
    "    transcriptions.append(transcribe(youtube_url, model))\n",
    "\n",
    "df = pd.DataFrame(transcriptions, columns=[\"title\", \"url\", \"text\"])\n",
    "df.to_csv(\"text.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing The Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Andrej Karpathy Tesla AI Self-Driving Optimus ...</td>\n",
       "      <td>https://www.youtube.com/watch?v=cdiD-9MMpb0</td>\n",
       "      <td>I think it's possible that physics has exploit...</td>\n",
       "      <td>47003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title   \n",
       "0  Andrej Karpathy Tesla AI Self-Driving Optimus ...  \\\n",
       "\n",
       "                                           url   \n",
       "0  https://www.youtube.com/watch?v=cdiD-9MMpb0  \\\n",
       "\n",
       "                                                text  tokens  \n",
       "0  I think it's possible that physics has exploit...   47003  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_TOKENS = 500\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "df = pd.read_csv(\"text.csv\", index_col=0)\n",
    "df[\"tokens\"] = df.text.apply(lambda x: len(tokenizer.encode(x)))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Andrej Karpathy Tesla AI Self-Driving Optimus ...</td>\n",
       "      <td>https://www.youtube.com/watch?v=cdiD-9MMpb0</td>\n",
       "      <td>I think it's possible that physics has exploit...</td>\n",
       "      <td>489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andrej Karpathy Tesla AI Self-Driving Optimus ...</td>\n",
       "      <td>https://www.youtube.com/watch?v=cdiD-9MMpb0</td>\n",
       "      <td>So basically I'm underselling it by a lot beca...</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Andrej Karpathy Tesla AI Self-Driving Optimus ...</td>\n",
       "      <td>https://www.youtube.com/watch?v=cdiD-9MMpb0</td>\n",
       "      <td>And when you give them a hard enough problem, ...</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andrej Karpathy Tesla AI Self-Driving Optimus ...</td>\n",
       "      <td>https://www.youtube.com/watch?v=cdiD-9MMpb0</td>\n",
       "      <td>Okay, so artificial neural networks are doing ...</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andrej Karpathy Tesla AI Self-Driving Optimus ...</td>\n",
       "      <td>https://www.youtube.com/watch?v=cdiD-9MMpb0</td>\n",
       "      <td>I almost understand everything else, I think i...</td>\n",
       "      <td>490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Andrej Karpathy Tesla AI Self-Driving Optimus ...</td>\n",
       "      <td>https://www.youtube.com/watch?v=cdiD-9MMpb0</td>\n",
       "      <td>It seems like there's a huge incentive to auto...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Andrej Karpathy Tesla AI Self-Driving Optimus ...</td>\n",
       "      <td>https://www.youtube.com/watch?v=cdiD-9MMpb0</td>\n",
       "      <td>Yeah, it's very confusing. I don't know if you...</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Andrej Karpathy Tesla AI Self-Driving Optimus ...</td>\n",
       "      <td>https://www.youtube.com/watch?v=cdiD-9MMpb0</td>\n",
       "      <td>Are you excited about that feature? Just AI's ...</td>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Andrej Karpathy Tesla AI Self-Driving Optimus ...</td>\n",
       "      <td>https://www.youtube.com/watch?v=cdiD-9MMpb0</td>\n",
       "      <td>And then for that, you sort of backtrack and s...</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Andrej Karpathy Tesla AI Self-Driving Optimus ...</td>\n",
       "      <td>https://www.youtube.com/watch?v=cdiD-9MMpb0</td>\n",
       "      <td>But I'm still pretty sure I'm an NPC. But an N...</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title   \n",
       "0    Andrej Karpathy Tesla AI Self-Driving Optimus ...  \\\n",
       "1    Andrej Karpathy Tesla AI Self-Driving Optimus ...   \n",
       "2    Andrej Karpathy Tesla AI Self-Driving Optimus ...   \n",
       "3    Andrej Karpathy Tesla AI Self-Driving Optimus ...   \n",
       "4    Andrej Karpathy Tesla AI Self-Driving Optimus ...   \n",
       "..                                                 ...   \n",
       "100  Andrej Karpathy Tesla AI Self-Driving Optimus ...   \n",
       "101  Andrej Karpathy Tesla AI Self-Driving Optimus ...   \n",
       "102  Andrej Karpathy Tesla AI Self-Driving Optimus ...   \n",
       "103  Andrej Karpathy Tesla AI Self-Driving Optimus ...   \n",
       "104  Andrej Karpathy Tesla AI Self-Driving Optimus ...   \n",
       "\n",
       "                                             url   \n",
       "0    https://www.youtube.com/watch?v=cdiD-9MMpb0  \\\n",
       "1    https://www.youtube.com/watch?v=cdiD-9MMpb0   \n",
       "2    https://www.youtube.com/watch?v=cdiD-9MMpb0   \n",
       "3    https://www.youtube.com/watch?v=cdiD-9MMpb0   \n",
       "4    https://www.youtube.com/watch?v=cdiD-9MMpb0   \n",
       "..                                           ...   \n",
       "100  https://www.youtube.com/watch?v=cdiD-9MMpb0   \n",
       "101  https://www.youtube.com/watch?v=cdiD-9MMpb0   \n",
       "102  https://www.youtube.com/watch?v=cdiD-9MMpb0   \n",
       "103  https://www.youtube.com/watch?v=cdiD-9MMpb0   \n",
       "104  https://www.youtube.com/watch?v=cdiD-9MMpb0   \n",
       "\n",
       "                                                  text  tokens  \n",
       "0    I think it's possible that physics has exploit...     489  \n",
       "1    So basically I'm underselling it by a lot beca...     500  \n",
       "2    And when you give them a hard enough problem, ...     500  \n",
       "3    Okay, so artificial neural networks are doing ...     497  \n",
       "4    I almost understand everything else, I think i...     490  \n",
       "..                                                 ...     ...  \n",
       "100  It seems like there's a huge incentive to auto...      12  \n",
       "101  Yeah, it's very confusing. I don't know if you...     461  \n",
       "102  Are you excited about that feature? Just AI's ...     477  \n",
       "103  And then for that, you sort of backtrack and s...     496  \n",
       "104  But I'm still pretty sure I'm an NPC. But an N...     194  \n",
       "\n",
       "[105 rows x 4 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_into_many(text, max_tokens):\n",
    "    # Split the text into sentences\n",
    "    sentences = text.split('. ')\n",
    "\n",
    "    # Get the number of tokens for each sentence\n",
    "    n_tokens = [len(tokenizer.encode(\" \" + sentence)) for sentence in sentences]\n",
    "    \n",
    "    chunks = []\n",
    "    tokens_so_far = 0\n",
    "    chunk = []\n",
    "\n",
    "    # Loop through the sentences and tokens joined together in a tuple\n",
    "    for sentence, token in zip(sentences, n_tokens):\n",
    "\n",
    "        # If the number of tokens so far plus the number of tokens in the current sentence is greater \n",
    "        # than the max number of tokens, then add the chunk to the list of chunks and reset\n",
    "        # the chunk and tokens so far\n",
    "        if tokens_so_far + token > max_tokens:\n",
    "            chunks.append(\". \".join(chunk) + \".\")\n",
    "            chunk = []\n",
    "            tokens_so_far = 0\n",
    "\n",
    "        # If the number of tokens in the current sentence is greater than the max number of \n",
    "        # tokens, go to the next sentence\n",
    "        if token > max_tokens:\n",
    "            continue\n",
    "\n",
    "        # Otherwise, add the sentence to the chunk and add the number of tokens to the total\n",
    "        chunk.append(sentence)\n",
    "        tokens_so_far += token + 1\n",
    "        \n",
    "    # Add the last chunk to the list of chunks\n",
    "    if chunk:\n",
    "        chunks.append(\". \".join(chunk) + \".\")\n",
    "\n",
    "    return chunks\n",
    "\n",
    "\n",
    "data = []\n",
    "for row in df.iterrows():\n",
    "    title = row[1][\"title\"]\n",
    "    url = row[1][\"url\"]\n",
    "    text = row[1][\"text\"]\n",
    "    tokens = row[1][\"tokens\"]\n",
    "\n",
    "    if tokens <= MAX_TOKENS:\n",
    "        data.append((title, url, text))\n",
    "    else:\n",
    "        for chunk in split_into_many(text, MAX_TOKENS):\n",
    "            data.append((title, url, chunk))\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"title\", \"url\", \"text\"])\n",
    "df[\"tokens\"] = df.text.apply(lambda x: len(tokenizer.encode(x)))\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Andrej Karpathy Tesla AI Self-Driving Optimus ...</td>\n",
       "      <td>https://www.youtube.com/watch?v=cdiD-9MMpb0</td>\n",
       "      <td>I think it's possible that physics has exploit...</td>\n",
       "      <td>489</td>\n",
       "      <td>[-0.004084109328687191, 0.0062974547035992146,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andrej Karpathy Tesla AI Self-Driving Optimus ...</td>\n",
       "      <td>https://www.youtube.com/watch?v=cdiD-9MMpb0</td>\n",
       "      <td>So basically I'm underselling it by a lot beca...</td>\n",
       "      <td>500</td>\n",
       "      <td>[-0.009419179521501064, -0.005321971606463194,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Andrej Karpathy Tesla AI Self-Driving Optimus ...</td>\n",
       "      <td>https://www.youtube.com/watch?v=cdiD-9MMpb0</td>\n",
       "      <td>And when you give them a hard enough problem, ...</td>\n",
       "      <td>500</td>\n",
       "      <td>[-0.00832328386604786, -0.0038060909137129784,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andrej Karpathy Tesla AI Self-Driving Optimus ...</td>\n",
       "      <td>https://www.youtube.com/watch?v=cdiD-9MMpb0</td>\n",
       "      <td>Okay, so artificial neural networks are doing ...</td>\n",
       "      <td>497</td>\n",
       "      <td>[-0.023266108706593513, -0.0021498766727745533...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andrej Karpathy Tesla AI Self-Driving Optimus ...</td>\n",
       "      <td>https://www.youtube.com/watch?v=cdiD-9MMpb0</td>\n",
       "      <td>I almost understand everything else, I think i...</td>\n",
       "      <td>490</td>\n",
       "      <td>[0.0174504816532135, -0.01404550950974226, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title   \n",
       "0  Andrej Karpathy Tesla AI Self-Driving Optimus ...  \\\n",
       "1  Andrej Karpathy Tesla AI Self-Driving Optimus ...   \n",
       "2  Andrej Karpathy Tesla AI Self-Driving Optimus ...   \n",
       "3  Andrej Karpathy Tesla AI Self-Driving Optimus ...   \n",
       "4  Andrej Karpathy Tesla AI Self-Driving Optimus ...   \n",
       "\n",
       "                                           url   \n",
       "0  https://www.youtube.com/watch?v=cdiD-9MMpb0  \\\n",
       "1  https://www.youtube.com/watch?v=cdiD-9MMpb0   \n",
       "2  https://www.youtube.com/watch?v=cdiD-9MMpb0   \n",
       "3  https://www.youtube.com/watch?v=cdiD-9MMpb0   \n",
       "4  https://www.youtube.com/watch?v=cdiD-9MMpb0   \n",
       "\n",
       "                                                text  tokens   \n",
       "0  I think it's possible that physics has exploit...     489  \\\n",
       "1  So basically I'm underselling it by a lot beca...     500   \n",
       "2  And when you give them a hard enough problem, ...     500   \n",
       "3  Okay, so artificial neural networks are doing ...     497   \n",
       "4  I almost understand everything else, I think i...     490   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [-0.004084109328687191, 0.0062974547035992146,...  \n",
       "1  [-0.009419179521501064, -0.005321971606463194,...  \n",
       "2  [-0.00832328386604786, -0.0038060909137129784,...  \n",
       "3  [-0.023266108706593513, -0.0021498766727745533...  \n",
       "4  [0.0174504816532135, -0.01404550950974226, -0....  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMBEDDING_ENGINE = \"text-embedding-ada-002\"\n",
    "\n",
    "df[\"embeddings\"] = df.text.apply(\n",
    "    lambda x: openai.Embedding.create(input=x, engine=EMBEDDING_ENGINE)[\"data\"][0][\n",
    "        \"embedding\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "df.to_csv(\"embeddings.csv\")\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WhoAmIResponse(username='aeea18e', user_label='youtube', projectname='1ed26d1')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PINECONE_INDEX = \"youtube\"\n",
    "\n",
    "df = pd.read_csv('embeddings.csv', index_col=0)\n",
    "df['embeddings'] = df.embeddings.apply(eval).apply(np.array)\n",
    "\n",
    "embedding_dimension = len(df.iloc[0][\"embeddings\"])\n",
    "\n",
    "pinecone.init(api_key=PINECONE_API_KEY, environment=PINECONE_API_ENV)\n",
    "pinecone.whoami()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if PINECONE_INDEX not in pinecone.list_indexes():\n",
    "    pinecone.create_index(\n",
    "        PINECONE_INDEX,\n",
    "        dimension=embedding_dimension,\n",
    "        metric=\"cosine\",\n",
    "        metadata_config={\"indexed\": [\"title\", \"url\"]},\n",
    "    )\n",
    "\n",
    "index = pinecone.Index(PINECONE_INDEX)\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"id\"] = [str(uuid4()) for _ in range(len(df))]\n",
    "\n",
    "batch_size = 2\n",
    "items = df.to_dict(orient=\"records\")\n",
    "\n",
    "for i in range(0, len(items), batch_size):\n",
    "    batch = items[i : min(len(items), i + batch_size)]\n",
    "\n",
    "    ids = [b[\"id\"] for b in batch]\n",
    "    embeddings = [list(b[\"embeddings\"]) for b in batch]\n",
    "    metadata = [{\"title\": b[\"title\"], \"url\": b[\"url\"], \"text\": b[\"text\"]} for b in batch]\n",
    "    index.upsert(vectors=list(zip(ids, embeddings, metadata)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 105}},\n",
       " 'total_vector_count': 105}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_LIMIT = 3000 # This is number of characters, not tokens\n",
    "COMPLETION_MODEL = \"gpt-3.5-turbo\"\n",
    "\n",
    "PROMPT = \"\"\"\n",
    "Answer the question based on the context below. If you can't \n",
    "answer the question, reply \"I don't know\".\n",
    "\n",
    "Context: [[CONTEXT]]\n",
    "\n",
    "Question: [[QUESTION]]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_prompt(query, prompt_limit=PROMPT_LIMIT):\n",
    "    response = openai.Embedding.create(input=[query], engine=EMBEDDING_ENGINE)\n",
    "    embedding = response[\"data\"][0][\"embedding\"]\n",
    "\n",
    "    response = index.query(embedding, top_k=3, include_metadata=True)\n",
    "\n",
    "    context = [m[\"metadata\"][\"text\"] for m in response[\"matches\"]]\n",
    "\n",
    "    for i in range(1, len(context)):\n",
    "        if len(PROMPT.replace(\"[[CONTEXT]]\", \"\\n\\n \\n\\n\".join(context[:i]))) >= prompt_limit:\n",
    "            prompt = PROMPT.replace(\n",
    "                \"[[CONTEXT]]\", \"\\n\\n \\n\\n\".join(context[: i - 1])\n",
    "            ).replace(\"[[QUESTION]]\", query)\n",
    "        elif i == len(context) - 1:\n",
    "            prompt = PROMPT.replace(\n",
    "                \"[[CONTEXT]]\", \"\\n\\n \\n\\n\".join(context)\n",
    "            ).replace(\"[[QUESTION]]\", query)\n",
    "\n",
    "    return prompt\n",
    "\n",
    "def get_answer(query):\n",
    "    prompt = get_prompt(query)\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=COMPLETION_MODEL,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"They talk about what the speaker has learned from working with Elon Musk, including how to run organizations efficiently and fight entropy in an organization. They also mention that Elon is a very efficient warrior in the fight against entropy in organizations and that he hates meetings and encourages people to skip them if they're not useful.\""
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_answer(\"What do they say about Elon Musk?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"They say that when you go to a conference or journal, no one discusses anything that's there because it's already irrelevant. The delay in publishing details of breakthrough performance can slow down the community's progress. They also mention that some prestigious venues still have value, but there is a little bit of delay that is part of their objective function.\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_answer(\"What do they say about problems with research papers?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.delete_index(PINECONE_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
